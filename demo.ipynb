{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# demo \n",
    "\n",
    "We will go through 3 examples:\n",
    "\n",
    "* **[text classification ](#text_classification)** - the goal is to classify a single sentence or short text.\n",
    "\n",
    "\n",
    "* **[text pair classification ](#text_pair_classification)** - the goal is to to classify a pair of sentences or short texts.\n",
    "\n",
    "\n",
    "* **[text pair regression ](#text_pair_regression)** - the goal is to predict a numerical value for a pair of sentences or short texts.\n",
    "\n",
    "\n",
    "#### A note on GPU cards...\n",
    "\n",
    "While its possible, it would be slow to run the examples without a GPU card of some sort. In addition , the `BERT` models(especially the large one) are pretty big so it helps to have more memory. \n",
    "\n",
    "The two biggest parameters you can change which will reduce the memory requirements significantly are:\n",
    "\n",
    "* `max_seq_length` - this is set to defualt at 128. But seting it to a smaller value like 96 or even 64 still gets good results on a lot of tasks.\n",
    "\n",
    "\n",
    "* `train_batch_size` - this is set to a default of 32. Cutting it in half should also still give good results.\n",
    "\n",
    "\n",
    "In addition to these two paremeters,  [huggingface/pytorch-pretrained-BERT](https://github.com/huggingface/pytorch-pretrained-BERT/blob/master/examples/run_classifier.py) has several options to reduce the GPU memory requirements which are passed through in `bert-sklearn`:\n",
    "\n",
    "* `gradient_accumulation_steps` - the default is 1. Setting it to 4, 8, or 16 will trade  memory for compute time. I use this a lot when I train BERT models on my laptop GPU.\n",
    "\n",
    "\n",
    "* `fp16` - the default is set to `False`. To enable half precision , you must install  [Nvidia apex](https://github.com/NVIDIA/apex). Then setting this option to `True` will cut the model memory load in half. I use this when i train on my laptop GPU as well.\n",
    "\n",
    "\n",
    "* `multiple gpus` - for a single machine with multiple GPUs ,following the huggingface port, the GPUs should be detected and will split the load  onto the multiple cards. \n",
    "\n",
    "\n",
    "* `distibuted training` - the huggingface port allows you to train across distributed GPUs. The parameters, i.e `local_rank`, are exposed in `bert-sklearn`. But this option has not been tested yet...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import csv\n",
    "import sys\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from bert_sklearn import BertClassifier\n",
    "from bert_sklearn import BertRegressor\n",
    "from bert_sklearn import load_model\n",
    "\n",
    "DATADIR = os.getcwd() + '/glue_examples/glue_data'\n",
    "\n",
    "def read_tsv(filename,quotechar=None):\n",
    "    with open(filename, \"r\", encoding='utf-8') as f:\n",
    "        return list(csv.reader(f,delimiter=\"\\t\",quotechar=quotechar))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a id='text_classification'></a>\n",
    "## text classification \n",
    "\n",
    "For single text/sentence classification we have the input data `X`, and target data `y` where:\n",
    "\n",
    "* `X` is a list, pandas Series, or numpy array of text data.\n",
    "\n",
    "\n",
    "* `y` is a list, pandas Series, or numpy array of text labels.\n",
    "\n",
    "For this example, we will use the **`Stanford Sentiment Treebank (SST-2)`** data set from the [GLUE benchmarks](https://gluebenchmark.com/). The `SST-2` task consists of semtences drawn from movie reviews and annotated for their sentiment. \n",
    "\n",
    "See [website](https://nlp.stanford.edu/sentiment/code.html) and [paper](https://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf) for more info.\n",
    "\n",
    "The input features are short sentences and the labels are the standard sentiment polarity of:\n",
    "*    0 for negative \n",
    "*    1 for positive.\n",
    "\n",
    "\n",
    "First download the data using the GLUE downloder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and extracting SST...\n",
      "\tCompleted!\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python3 ./glue_examples/download_glue_data.py --data_dir ./glue_examples//glue_data --tasks SST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SST-2 train data size: 67349 \n",
      "SST-2 dev data size: 872 \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hide new secretions from the parental units</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>contains no wit , only labored gags</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>that loves its characters and communicates som...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>remains utterly satisfied to remain the same t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>on the worst revenge-of-the-nerds clichés the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0       hide new secretions from the parental units       0\n",
       "1               contains no wit , only labored gags       0\n",
       "2  that loves its characters and communicates som...      1\n",
       "3  remains utterly satisfied to remain the same t...      0\n",
       "4  on the worst revenge-of-the-nerds clichés the ...      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "SST-2 train data size: 67349 \n",
    "SST-2 dev data size: 872 \n",
    "\"\"\"\n",
    "def get_sst_data(train_file = DATADIR + '/SST-2/train.tsv',\n",
    "                dev_file  = DATADIR + '/SST-2/dev.tsv'):\n",
    "    \n",
    "    train = pd.read_csv(train_file, sep='\\t',  encoding = 'utf8',keep_default_na=False)\n",
    "    train.columns=['text','label']\n",
    "    print(\"SST-2 train data size: %d \"%(len(train)))\n",
    "    \n",
    "    dev = pd.read_csv(dev_file, sep='\\t',  encoding = 'utf8',keep_default_na=False)\n",
    "    dev.columns=['text','label']\n",
    "    print(\"SST-2 dev data size: %d \"%(len(dev)))\n",
    "    label_list = np.unique(train['label'])\n",
    "    \n",
    "    return train,dev,label_list\n",
    "\n",
    "train,dev,label_list = get_sst_data()\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### setup data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets subsample data  for the demo\n",
    "train = train.sample(1000,random_state=42)\n",
    "\n",
    "X_train = train['text']\n",
    "y_train = train['label']\n",
    "\n",
    "# use the dev set for testing\n",
    "test = dev\n",
    "X_test = test['text']\n",
    "y_test = test['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### define model\n",
    "\n",
    "We will set up a classifier with the defualt settings, but lets reduce `max_sequence_length` from the default 128, so it can run on smaller GPU. This config should be ~ 5Gb:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn classifier...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertClassifier(bert_model='bert-base-uncased', epochs=3, eval_batch_size=8,\n",
       "        fp16=False, gradient_accumulation_steps=1, label_list=None,\n",
       "        learning_rate=2e-05, local_rank=-1, logfile='bert_sklearn.log',\n",
       "        loss_scale=0, max_seq_length=64, num_mlp_hiddens=500,\n",
       "        num_mlp_layers=0, random_state=42, restore_file=None,\n",
       "        train_batch_size=32, use_cuda=True, validation_fraction=0.1,\n",
       "        warmup_proportion=0.1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertClassifier(max_seq_length=64)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fit  model on train data\n",
    "The fit routine :\n",
    "* loads the pretrained BERT model\n",
    "* Uses 10% of the data for validation and finetunes BERT on the remainder for 3 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "train data size: 900, validation data size: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 29/29 [00:12<00:00,  2.78it/s, loss=0.623]\n",
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train loss : 0.6230, Val loss: 0.6812, Val accy = 65.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 29/29 [00:12<00:00,  2.87it/s, loss=0.237]\n",
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train loss : 0.2366, Val loss: 0.4520, Val accy = 83.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 29/29 [00:12<00:00,  2.86it/s, loss=0.121]\n",
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train loss : 0.1209, Val loss: 0.4515, Val accy = 83.00%\n",
      "CPU times: user 30.7 s, sys: 15.2 s, total: 46 s\n",
      "Wall time: 47 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertClassifier(bert_model='bert-base-uncased', epochs=3, eval_batch_size=8,\n",
       "        fp16=False, gradient_accumulation_steps=1,\n",
       "        label_list=array([0, 1]), learning_rate=2e-05, local_rank=-1,\n",
       "        logfile='bert_sklearn.log', loss_scale=0, max_seq_length=64,\n",
       "        num_mlp_hiddens=500, num_mlp_layers=0, random_state=42,\n",
       "        restore_file=None, train_batch_size=32, use_cuda=True,\n",
       "        validation_fraction=0.1, warmup_proportion=0.1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### score and make predictions on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   0%|          | 0/109 [00:00<?, ?it/s]       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test loss: 0.3214, Test accuracy = 87.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   0%|          | 0/109 [00:00<?, ?it/s]          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class prob estimates:\n",
      " [[0.01246537 0.98753464]\n",
      " [0.9561755  0.04382455]\n",
      " [0.02255277 0.9774473 ]\n",
      " ...\n",
      " [0.85820186 0.14179818]\n",
      " [0.78386265 0.21613738]\n",
      " [0.10148279 0.89851725]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.39%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.91      0.88       428\n",
      "    positive       0.91      0.84      0.87       444\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       872\n",
      "   macro avg       0.88      0.87      0.87       872\n",
      "weighted avg       0.88      0.87      0.87       872\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# score model\n",
    "accy = model.score(X_test, y_test,verbose=True)\n",
    "\n",
    "# make class probability predicts\n",
    "y_prob = model.predict_proba(X_test)\n",
    "print(\"class prob estimates:\\n\", y_prob)\n",
    "\n",
    "# make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy: %0.2f%%\"%(metrics.accuracy_score(y_pred,y_test) * 100))\n",
    "\n",
    "target_names = ['negative', 'positive']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### save/load model from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from /data/test.bin...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 407873900/407873900 [00:28<00:00, 14080940.67B/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to linear classifier/regressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Testing:   0%|          | 0/109 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn classifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test loss: 0.3214, Test accuracy = 87.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "#save model to disk\n",
    "savefile='/data/test.bin'\n",
    "model.save(savefile)\n",
    "\n",
    "# load model from disk\n",
    "new_model = load_model(savefile)\n",
    "\n",
    "# predict with new model\n",
    "accy = new_model.score(X_test, y_test,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### options\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('bert-base-uncased',\n",
       " 'bert-large-uncased',\n",
       " 'bert-base-cased',\n",
       " 'bert-large-cased',\n",
       " 'bert-base-multilingual-uncased',\n",
       " 'bert-base-multilingual-cased',\n",
       " 'bert-base-chinese')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bert_sklearn import SUPPORTED_MODELS\n",
    "SUPPORTED_MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try the larger bert model : `'bert-large-uncased'`\n",
    "Lets also accumulate gradients to avoid running out of memory.. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn classifier...\n",
      "Loading bert-large-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "train data size: 1000, validation data size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 500/500 [01:02<00:00,  7.75it/s, loss=0.718]\n",
      "Training: 100%|██████████| 500/500 [01:03<00:00,  7.72it/s, loss=0.386]\n",
      "Training: 100%|██████████| 500/500 [01:07<00:00,  7.39it/s, loss=0.211]\n",
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test loss: 0.2742, Test accuracy = 90.37%\n",
      "CPU times: user 2min 57s, sys: 50.8 s, total: 3min 48s\n",
      "Wall time: 3min 48s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# try large bert model with different options\n",
    "model = BertClassifier(bert_model='bert-large-uncased',\n",
    "                       max_seq_length=64,\n",
    "                       epochs=3,\n",
    "                       learning_rate=2e-5,\n",
    "                       validation_fraction=0,\n",
    "                       gradient_accumulation_steps=16)\n",
    "\n",
    "# fit model\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "# score model\n",
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='text_pair_classification'></a>\n",
    "\n",
    "## text pair classification\n",
    "\n",
    "For text pair classification, we have input data `X`, and target data `y` where :\n",
    "\n",
    "* `X` is a list, pandas dataframe, or numpy array of text pairs (`text_a`, `text_b`) .\n",
    "\n",
    "\n",
    "* `y` is a list, pandas Series, or numpy array of text labels\n",
    "\n",
    "For this example, we will use the **`Quora Question Pair(QQP)`** data set from the [GLUE benchmarks](https://gluebenchmark.com/). This data consists of sentences pairs from the Quora website labeled as duplicate or not. See [original release post](https://data.quora.com/First-Quora-Dataset-Release-Question-Pairs) for more info.\n",
    "\n",
    "The input features are pairs of questions (text_a,text_b) along with the labels :\n",
    "*    0 if `text_a` and `text_b` are not duplicates\n",
    "\n",
    "*    1 if `text_a` and `text_b` are duplicates\n",
    "\n",
    "Lets download the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and extracting QQP...\n",
      "\tCompleted!\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python3 ./glue_examples/download_glue_data.py --data_dir ./glue_examples//glue_data --tasks QQP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QQP train data size: 363849 \n",
      "QQP dev data size: 40430 \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_a</th>\n",
       "      <th>text_b</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How is the life of a math student? Could you d...</td>\n",
       "      <td>Which level of prepration is enough for the ex...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How do I control my horny emotions?</td>\n",
       "      <td>How do you control your horniness?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What causes stool color to change to yellow?</td>\n",
       "      <td>What can cause stool to come out as little balls?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What can one do after MBBS?</td>\n",
       "      <td>What do i do after my MBBS ?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Where can I find a power outlet for my laptop ...</td>\n",
       "      <td>Would a second airport in Sydney, Australia be...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              text_a  \\\n",
       "0  How is the life of a math student? Could you d...   \n",
       "1                How do I control my horny emotions?   \n",
       "2       What causes stool color to change to yellow?   \n",
       "3                        What can one do after MBBS?   \n",
       "4  Where can I find a power outlet for my laptop ...   \n",
       "\n",
       "                                              text_b label  \n",
       "0  Which level of prepration is enough for the ex...     0  \n",
       "1                 How do you control your horniness?     1  \n",
       "2  What can cause stool to come out as little balls?     0  \n",
       "3                       What do i do after my MBBS ?     1  \n",
       "4  Would a second airport in Sydney, Australia be...     0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "QQP train data size: 363849 \n",
    "QQP dev data size: 40430 \n",
    "\"\"\"\n",
    "   \n",
    "def get_quora_df(filename):\n",
    "    rows = read_tsv(filename)\n",
    "    df=pd.DataFrame(rows[1:],columns=rows[0])\n",
    "    df=df[['question1','question2','is_duplicate']]\n",
    "    df = df[pd.notnull(df['is_duplicate'])]\n",
    "    df.columns=['text_a','text_b','label']\n",
    "    return df\n",
    "\n",
    "def get_quora_data(train_file = DATADIR+'/QQP/train.tsv', \n",
    "                   dev_file =  DATADIR+'/QQP/dev.tsv'):\n",
    "    train = get_quora_df(train_file)\n",
    "    print(\"QQP train data size: %d \"%(len(train)))\n",
    "    dev = get_quora_df(dev_file)\n",
    "    print(\"QQP dev data size: %d \"%(len(dev)))\n",
    "\n",
    "    label_list = np.unique(train['label'].values)\n",
    "    return train,dev,label_list\n",
    "\n",
    "train,dev,label_list = get_quora_data()\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn classifier...\n",
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "train data size: 9000, validation data size: 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 282/282 [02:02<00:00,  2.65it/s, loss=0.517]\n",
      "                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train loss : 0.5173, Val loss: 0.4309, Val accy = 78.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 282/282 [02:15<00:00,  2.09it/s, loss=0.311]\n",
      "                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train loss : 0.3113, Val loss: 0.4210, Val accy = 80.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 282/282 [02:29<00:00,  2.36it/s, loss=0.235]\n",
      "                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train loss : 0.2346, Val loss: 0.4475, Val accy = 80.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test loss: 0.4171, Test accuracy = 81.91%\n",
      "CPU times: user 5min 25s, sys: 2min 46s, total: 8min 11s\n",
      "Wall time: 8min 12s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# subsample data for demo\n",
    "n = 10000\n",
    "train = train.sample(n=n,random_state=42)\n",
    "dev = dev.sample(n=n,random_state=42)\n",
    "\n",
    "X_train = train[['text_a','text_b']]\n",
    "y_train = train['label']\n",
    "\n",
    "# use the dev set for testing...\n",
    "test = dev\n",
    "X_test = test[['text_a','text_b']]\n",
    "y_test = test['label']\n",
    "\n",
    "# define model\n",
    "model = BertClassifier(max_seq_length=64)\n",
    "\n",
    "# fit model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# score model\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='text_pair_regression'></a>\n",
    "\n",
    "## text pair regression  \n",
    "\n",
    "For text pair regression we have input data `X`, and target data `y` where :\n",
    "\n",
    "* `X` is a list, pandas dataframe, or numpy array of text pairs (`text_a`, `text_b`) .\n",
    "\n",
    "\n",
    "* `y` is a list, pandas Series, or numpy array of floats.\n",
    "\n",
    "\n",
    "For this example, we will use the **`STS-B`** data set from [GLUE benchmarks](https://gluebenchmark.com/). The data consists of sentence pairs drawn from news headlines and image captions with annotated similarity scores ranging from 1 to 5.\n",
    "\n",
    "See [website](http://ixa2.si.ehu.es/stswiki/index.php/STSbenchmark) and [paper](http://www.aclweb.org/anthology/S/S17/S17-2001.pdf) for more info.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STS-B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and extracting STS...\n",
      "\tCompleted!\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python3 ./glue_examples/download_glue_data.py --data_dir ./glue_examples//glue_data --tasks STS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STS-B train data size: 5749 \n",
      "STS-B dev data size: 1500 \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_a</th>\n",
       "      <th>text_b</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A plane is taking off.</td>\n",
       "      <td>An air plane is taking off.</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A man is playing a large flute.</td>\n",
       "      <td>A man is playing a flute.</td>\n",
       "      <td>3.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A man is spreading shreded cheese on a pizza.</td>\n",
       "      <td>A man is spreading shredded cheese on an uncoo...</td>\n",
       "      <td>3.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Three men are playing chess.</td>\n",
       "      <td>Two men are playing chess.</td>\n",
       "      <td>2.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A man is playing the cello.</td>\n",
       "      <td>A man seated is playing the cello.</td>\n",
       "      <td>4.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          text_a  \\\n",
       "0                         A plane is taking off.   \n",
       "1                A man is playing a large flute.   \n",
       "2  A man is spreading shreded cheese on a pizza.   \n",
       "3                   Three men are playing chess.   \n",
       "4                    A man is playing the cello.   \n",
       "\n",
       "                                              text_b  label  \n",
       "0                        An air plane is taking off.   5.00  \n",
       "1                          A man is playing a flute.   3.80  \n",
       "2  A man is spreading shredded cheese on an uncoo...   3.80  \n",
       "3                         Two men are playing chess.   2.60  \n",
       "4                 A man seated is playing the cello.   4.25  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "STS-B train data size: 5749 \n",
    "STS-B dev data size: 1500 \n",
    "\"\"\"\n",
    "def get_sts_b_df(filename):\n",
    "    rows = read_tsv(filename)\n",
    "    df=pd.DataFrame(rows[1:],columns=rows[0])\n",
    "    df=df[['sentence1','sentence2','score']]    \n",
    "    df.columns=['text_a','text_b','label']\n",
    "    df.label = pd.to_numeric(df.label)\n",
    "    df = df[pd.notnull(df['label'])]                \n",
    "    return df\n",
    "\n",
    "def get_sts_b_data(train_file = DATADIR + '/STS-B/train.tsv',\n",
    "                   dev_file ='/data/glue_data/STS-B/dev.tsv',\n",
    "                   nrows=None):\n",
    "    train = get_sts_b_df(train_file)\n",
    "    print(\"STS-B train data size: %d \"%(len(train)))    \n",
    "    dev   = get_sts_b_df(dev_file)\n",
    "    print(\"STS-B dev data size: %d \"%(len(dev)))  \n",
    "    return train,dev\n",
    "\n",
    "train,dev = get_sts_b_data()\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn regressor...\n",
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "train data size: 900, validation data size: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 29/29 [00:12<00:00,  2.92it/s, loss=3.53]\n",
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train loss : 3.5257, Val loss: 1.7551, Val accy = 63.68%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 29/29 [00:12<00:00,  2.89it/s, loss=0.766]\n",
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train loss : 0.7659, Val loss: 0.7042, Val accy = 80.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 29/29 [00:12<00:00,  2.90it/s, loss=0.511]\n",
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train loss : 0.5107, Val loss: 0.7286, Val accy = 81.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   0%|          | 0/125 [00:00<?, ?it/s]       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test loss: 0.6663, Test accuracy = 84.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson : 84.17\n",
      "CPU times: user 36.2 s, sys: 16.8 s, total: 53 s\n",
      "Wall time: 54.1 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "train = train.sample(n=1000,random_state=42)\n",
    "dev = dev.sample(n=1000,random_state=42)\n",
    "\n",
    "\n",
    "X_train = train[['text_a','text_b']]\n",
    "y_train = train['label']\n",
    "\n",
    "# use the dev set for testing...\n",
    "test = dev\n",
    "X_test = test[['text_a','text_b']]\n",
    "y_test = test['label']\n",
    "\n",
    "# define model\n",
    "model = BertRegressor()\n",
    "model.max_seq_length = 64\n",
    "\n",
    "# fit\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# score on test data\n",
    "model.score(X_test, y_test)\n",
    "\n",
    "# predict on test data \n",
    "y_pred = model.predict(X_test)\n",
    "pearson_accy = pearsonr(y_pred,y_test)[0] * 100\n",
    "print(\"Pearson : %0.2f\"%(pearson_accy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
